{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pip in ./.venv/lib/python3.12/site-packages (25.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install --upgrade pip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pandas\n",
      "  Using cached pandas-2.3.2-cp312-cp312-macosx_11_0_arm64.whl.metadata (91 kB)\n",
      "Collecting datetime\n",
      "  Using cached DateTime-5.5-py3-none-any.whl.metadata (33 kB)\n",
      "Collecting matplotlib\n",
      "  Using cached matplotlib-3.10.6-cp312-cp312-macosx_11_0_arm64.whl.metadata (11 kB)\n",
      "Collecting seaborn\n",
      "  Using cached seaborn-0.13.2-py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting neuralprophet\n",
      "  Using cached neuralprophet-0.8.0-py3-none-any.whl.metadata (9.1 kB)\n",
      "Collecting scikit-learn\n",
      "  Using cached scikit_learn-1.7.2-cp312-cp312-macosx_12_0_arm64.whl.metadata (11 kB)\n",
      "Collecting torch\n",
      "  Using cached torch-2.8.0-cp312-none-macosx_11_0_arm64.whl.metadata (30 kB)\n",
      "Collecting wxPython\n",
      "  Downloading wxpython-4.2.3-cp312-cp312-macosx_11_0_arm64.whl.metadata (3.6 kB)\n",
      "Collecting numpy>=1.26.0 (from pandas)\n",
      "  Downloading numpy-2.3.3-cp312-cp312-macosx_14_0_arm64.whl.metadata (62 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in ./.venv/lib/python3.12/site-packages (from pandas) (2.9.0.post0)\n",
      "Collecting pytz>=2020.1 (from pandas)\n",
      "  Downloading pytz-2025.2-py2.py3-none-any.whl.metadata (22 kB)\n",
      "Collecting tzdata>=2022.7 (from pandas)\n",
      "  Downloading tzdata-2025.2-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Collecting zope.interface (from datetime)\n",
      "  Downloading zope.interface-7.2-cp312-cp312-macosx_11_0_arm64.whl.metadata (44 kB)\n",
      "Collecting contourpy>=1.0.1 (from matplotlib)\n",
      "  Downloading contourpy-1.3.3-cp312-cp312-macosx_11_0_arm64.whl.metadata (5.5 kB)\n",
      "Collecting cycler>=0.10 (from matplotlib)\n",
      "  Downloading cycler-0.12.1-py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting fonttools>=4.22.0 (from matplotlib)\n",
      "  Downloading fonttools-4.59.2-cp312-cp312-macosx_10_13_universal2.whl.metadata (109 kB)\n",
      "Collecting kiwisolver>=1.3.1 (from matplotlib)\n",
      "  Downloading kiwisolver-1.4.9-cp312-cp312-macosx_11_0_arm64.whl.metadata (6.3 kB)\n",
      "Requirement already satisfied: packaging>=20.0 in ./.venv/lib/python3.12/site-packages (from matplotlib) (25.0)\n",
      "Collecting pillow>=8 (from matplotlib)\n",
      "  Downloading pillow-11.3.0-cp312-cp312-macosx_11_0_arm64.whl.metadata (9.0 kB)\n",
      "Collecting pyparsing>=2.3.1 (from matplotlib)\n",
      "  Downloading pyparsing-3.2.3-py3-none-any.whl.metadata (5.0 kB)\n",
      "Collecting captum>=0.6.0 (from neuralprophet)\n",
      "  Downloading captum-0.8.0-py3-none-any.whl.metadata (26 kB)\n",
      "Collecting holidays>=0.41 (from neuralprophet)\n",
      "  Downloading holidays-0.80-py3-none-any.whl.metadata (48 kB)\n",
      "Collecting nbformat<6.0.0,>=5.8.0 (from neuralprophet)\n",
      "  Downloading nbformat-5.10.4-py3-none-any.whl.metadata (3.6 kB)\n",
      "Collecting numpy>=1.26.0 (from pandas)\n",
      "  Downloading numpy-1.26.4-cp312-cp312-macosx_11_0_arm64.whl.metadata (61 kB)\n",
      "Collecting plotly<6.0.0,>=5.13.1 (from neuralprophet)\n",
      "  Downloading plotly-5.24.1-py3-none-any.whl.metadata (7.3 kB)\n",
      "Collecting pytorch-lightning<2.0.0,>=1.9.4 (from neuralprophet)\n",
      "  Downloading pytorch_lightning-1.9.5-py3-none-any.whl.metadata (23 kB)\n",
      "Collecting tensorboard<3.0.0,>=2.11.2 (from neuralprophet)\n",
      "  Downloading tensorboard-2.20.0-py3-none-any.whl.metadata (1.8 kB)\n",
      "Collecting torchmetrics<2.0.0,>=1.0.0 (from neuralprophet)\n",
      "  Downloading torchmetrics-1.8.2-py3-none-any.whl.metadata (22 kB)\n",
      "Collecting typing-extensions<5.0.0,>=4.5.0 (from neuralprophet)\n",
      "  Downloading typing_extensions-4.15.0-py3-none-any.whl.metadata (3.3 kB)\n",
      "Collecting filelock (from torch)\n",
      "  Downloading filelock-3.19.1-py3-none-any.whl.metadata (2.1 kB)\n",
      "Collecting setuptools (from torch)\n",
      "  Downloading setuptools-80.9.0-py3-none-any.whl.metadata (6.6 kB)\n",
      "Collecting sympy>=1.13.3 (from torch)\n",
      "  Downloading sympy-1.14.0-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting networkx (from torch)\n",
      "  Downloading networkx-3.5-py3-none-any.whl.metadata (6.3 kB)\n",
      "Collecting jinja2 (from torch)\n",
      "  Downloading jinja2-3.1.6-py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting fsspec (from torch)\n",
      "  Downloading fsspec-2025.9.0-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting fastjsonschema>=2.15 (from nbformat<6.0.0,>=5.8.0->neuralprophet)\n",
      "  Downloading fastjsonschema-2.21.2-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting jsonschema>=2.6 (from nbformat<6.0.0,>=5.8.0->neuralprophet)\n",
      "  Downloading jsonschema-4.25.1-py3-none-any.whl.metadata (7.6 kB)\n",
      "Requirement already satisfied: jupyter-core!=5.0.*,>=4.12 in ./.venv/lib/python3.12/site-packages (from nbformat<6.0.0,>=5.8.0->neuralprophet) (5.8.1)\n",
      "Requirement already satisfied: traitlets>=5.1 in ./.venv/lib/python3.12/site-packages (from nbformat<6.0.0,>=5.8.0->neuralprophet) (5.14.3)\n",
      "Collecting tenacity>=6.2.0 (from plotly<6.0.0,>=5.13.1->neuralprophet)\n",
      "  Downloading tenacity-9.1.2-py3-none-any.whl.metadata (1.2 kB)\n",
      "Collecting tqdm>=4.57.0 (from pytorch-lightning<2.0.0,>=1.9.4->neuralprophet)\n",
      "  Downloading tqdm-4.67.1-py3-none-any.whl.metadata (57 kB)\n",
      "Collecting PyYAML>=5.4 (from pytorch-lightning<2.0.0,>=1.9.4->neuralprophet)\n",
      "  Downloading PyYAML-6.0.2-cp312-cp312-macosx_11_0_arm64.whl.metadata (2.1 kB)\n",
      "Collecting lightning-utilities>=0.6.0.post0 (from pytorch-lightning<2.0.0,>=1.9.4->neuralprophet)\n",
      "  Downloading lightning_utilities-0.15.2-py3-none-any.whl.metadata (5.7 kB)\n",
      "Collecting absl-py>=0.4 (from tensorboard<3.0.0,>=2.11.2->neuralprophet)\n",
      "  Downloading absl_py-2.3.1-py3-none-any.whl.metadata (3.3 kB)\n",
      "Collecting grpcio>=1.48.2 (from tensorboard<3.0.0,>=2.11.2->neuralprophet)\n",
      "  Downloading grpcio-1.74.0-cp312-cp312-macosx_11_0_universal2.whl.metadata (3.8 kB)\n",
      "Collecting markdown>=2.6.8 (from tensorboard<3.0.0,>=2.11.2->neuralprophet)\n",
      "  Downloading markdown-3.9-py3-none-any.whl.metadata (5.1 kB)\n",
      "Collecting protobuf!=4.24.0,>=3.19.6 (from tensorboard<3.0.0,>=2.11.2->neuralprophet)\n",
      "  Downloading protobuf-6.32.1-cp39-abi3-macosx_10_9_universal2.whl.metadata (593 bytes)\n",
      "Collecting tensorboard-data-server<0.8.0,>=0.7.0 (from tensorboard<3.0.0,>=2.11.2->neuralprophet)\n",
      "  Downloading tensorboard_data_server-0.7.2-py3-none-any.whl.metadata (1.1 kB)\n",
      "Collecting werkzeug>=1.0.1 (from tensorboard<3.0.0,>=2.11.2->neuralprophet)\n",
      "  Downloading werkzeug-3.1.3-py3-none-any.whl.metadata (3.7 kB)\n",
      "Collecting scipy>=1.8.0 (from scikit-learn)\n",
      "  Downloading scipy-1.16.2-cp312-cp312-macosx_14_0_arm64.whl.metadata (62 kB)\n",
      "Collecting joblib>=1.2.0 (from scikit-learn)\n",
      "  Downloading joblib-1.5.2-py3-none-any.whl.metadata (5.6 kB)\n",
      "Collecting threadpoolctl>=3.1.0 (from scikit-learn)\n",
      "  Downloading threadpoolctl-3.6.0-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting aiohttp!=4.0.0a0,!=4.0.0a1 (from fsspec[http]>2021.06.0->pytorch-lightning<2.0.0,>=1.9.4->neuralprophet)\n",
      "  Downloading aiohttp-3.12.15-cp312-cp312-macosx_11_0_arm64.whl.metadata (7.7 kB)\n",
      "Collecting aiohappyeyeballs>=2.5.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning<2.0.0,>=1.9.4->neuralprophet)\n",
      "  Downloading aiohappyeyeballs-2.6.1-py3-none-any.whl.metadata (5.9 kB)\n",
      "Collecting aiosignal>=1.4.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning<2.0.0,>=1.9.4->neuralprophet)\n",
      "  Downloading aiosignal-1.4.0-py3-none-any.whl.metadata (3.7 kB)\n",
      "Collecting attrs>=17.3.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning<2.0.0,>=1.9.4->neuralprophet)\n",
      "  Downloading attrs-25.3.0-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting frozenlist>=1.1.1 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning<2.0.0,>=1.9.4->neuralprophet)\n",
      "  Downloading frozenlist-1.7.0-cp312-cp312-macosx_11_0_arm64.whl.metadata (18 kB)\n",
      "Collecting multidict<7.0,>=4.5 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning<2.0.0,>=1.9.4->neuralprophet)\n",
      "  Downloading multidict-6.6.4-cp312-cp312-macosx_11_0_arm64.whl.metadata (5.3 kB)\n",
      "Collecting propcache>=0.2.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning<2.0.0,>=1.9.4->neuralprophet)\n",
      "  Downloading propcache-0.3.2-cp312-cp312-macosx_11_0_arm64.whl.metadata (12 kB)\n",
      "Collecting yarl<2.0,>=1.17.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning<2.0.0,>=1.9.4->neuralprophet)\n",
      "  Downloading yarl-1.20.1-cp312-cp312-macosx_11_0_arm64.whl.metadata (73 kB)\n",
      "Collecting idna>=2.0 (from yarl<2.0,>=1.17.0->aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning<2.0.0,>=1.9.4->neuralprophet)\n",
      "  Downloading idna-3.10-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting jsonschema-specifications>=2023.03.6 (from jsonschema>=2.6->nbformat<6.0.0,>=5.8.0->neuralprophet)\n",
      "  Downloading jsonschema_specifications-2025.9.1-py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting referencing>=0.28.4 (from jsonschema>=2.6->nbformat<6.0.0,>=5.8.0->neuralprophet)\n",
      "  Downloading referencing-0.36.2-py3-none-any.whl.metadata (2.8 kB)\n",
      "Collecting rpds-py>=0.7.1 (from jsonschema>=2.6->nbformat<6.0.0,>=5.8.0->neuralprophet)\n",
      "  Downloading rpds_py-0.27.1-cp312-cp312-macosx_11_0_arm64.whl.metadata (4.2 kB)\n",
      "Requirement already satisfied: platformdirs>=2.5 in ./.venv/lib/python3.12/site-packages (from jupyter-core!=5.0.*,>=4.12->nbformat<6.0.0,>=5.8.0->neuralprophet) (4.4.0)\n",
      "Requirement already satisfied: six>=1.5 in ./.venv/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Collecting mpmath<1.4,>=1.1.0 (from sympy>=1.13.3->torch)\n",
      "  Downloading mpmath-1.3.0-py3-none-any.whl.metadata (8.6 kB)\n",
      "Collecting MarkupSafe>=2.1.1 (from werkzeug>=1.0.1->tensorboard<3.0.0,>=2.11.2->neuralprophet)\n",
      "  Downloading MarkupSafe-3.0.2-cp312-cp312-macosx_11_0_arm64.whl.metadata (4.0 kB)\n",
      "Downloading pandas-2.3.2-cp312-cp312-macosx_11_0_arm64.whl (10.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.7/10.7 MB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m  \u001b[33m0:00:02\u001b[0meta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading DateTime-5.5-py3-none-any.whl (52 kB)\n",
      "Downloading matplotlib-3.10.6-cp312-cp312-macosx_11_0_arm64.whl (8.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.1/8.1 MB\u001b[0m \u001b[31m16.9 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading seaborn-0.13.2-py3-none-any.whl (294 kB)\n",
      "Downloading neuralprophet-0.8.0-py3-none-any.whl (145 kB)\n",
      "Downloading torch-2.8.0-cp312-none-macosx_11_0_arm64.whl (73.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m73.6/73.6 MB\u001b[0m \u001b[31m23.5 MB/s\u001b[0m  \u001b[33m0:00:03\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading nbformat-5.10.4-py3-none-any.whl (78 kB)\n",
      "Downloading numpy-1.26.4-cp312-cp312-macosx_11_0_arm64.whl (13.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.7/13.7 MB\u001b[0m \u001b[31m22.9 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0meta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading plotly-5.24.1-py3-none-any.whl (19.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19.1/19.1 MB\u001b[0m \u001b[31m21.4 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading pytorch_lightning-1.9.5-py3-none-any.whl (829 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m829.5/829.5 kB\u001b[0m \u001b[31m15.6 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading tensorboard-2.20.0-py3-none-any.whl (5.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.5/5.5 MB\u001b[0m \u001b[31m23.5 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading tensorboard_data_server-0.7.2-py3-none-any.whl (2.4 kB)\n",
      "Downloading torchmetrics-1.8.2-py3-none-any.whl (983 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m983.2/983.2 kB\u001b[0m \u001b[31m21.7 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading typing_extensions-4.15.0-py3-none-any.whl (44 kB)\n",
      "Downloading scikit_learn-1.7.2-cp312-cp312-macosx_12_0_arm64.whl (8.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.6/8.6 MB\u001b[0m \u001b[31m23.4 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading wxpython-4.2.3-cp312-cp312-macosx_11_0_arm64.whl (17.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.9/17.9 MB\u001b[0m \u001b[31m24.3 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading absl_py-2.3.1-py3-none-any.whl (135 kB)\n",
      "Downloading captum-0.8.0-py3-none-any.whl (1.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m12.3 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading contourpy-1.3.3-cp312-cp312-macosx_11_0_arm64.whl (273 kB)\n",
      "Downloading cycler-0.12.1-py3-none-any.whl (8.3 kB)\n",
      "Downloading fastjsonschema-2.21.2-py3-none-any.whl (24 kB)\n",
      "Downloading fonttools-4.59.2-cp312-cp312-macosx_10_13_universal2.whl (2.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.8/2.8 MB\u001b[0m \u001b[31m20.4 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading fsspec-2025.9.0-py3-none-any.whl (199 kB)\n",
      "Downloading aiohttp-3.12.15-cp312-cp312-macosx_11_0_arm64.whl (469 kB)\n",
      "Downloading multidict-6.6.4-cp312-cp312-macosx_11_0_arm64.whl (43 kB)\n",
      "Downloading yarl-1.20.1-cp312-cp312-macosx_11_0_arm64.whl (89 kB)\n",
      "Downloading aiohappyeyeballs-2.6.1-py3-none-any.whl (15 kB)\n",
      "Downloading aiosignal-1.4.0-py3-none-any.whl (7.5 kB)\n",
      "Downloading attrs-25.3.0-py3-none-any.whl (63 kB)\n",
      "Downloading frozenlist-1.7.0-cp312-cp312-macosx_11_0_arm64.whl (46 kB)\n",
      "Downloading grpcio-1.74.0-cp312-cp312-macosx_11_0_universal2.whl (11.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.0/11.0 MB\u001b[0m \u001b[31m23.8 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0meta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading holidays-0.80-py3-none-any.whl (1.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m15.4 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading idna-3.10-py3-none-any.whl (70 kB)\n",
      "Downloading joblib-1.5.2-py3-none-any.whl (308 kB)\n",
      "Downloading jsonschema-4.25.1-py3-none-any.whl (90 kB)\n",
      "Downloading jsonschema_specifications-2025.9.1-py3-none-any.whl (18 kB)\n",
      "Downloading kiwisolver-1.4.9-cp312-cp312-macosx_11_0_arm64.whl (64 kB)\n",
      "Downloading lightning_utilities-0.15.2-py3-none-any.whl (29 kB)\n",
      "Downloading markdown-3.9-py3-none-any.whl (107 kB)\n",
      "Downloading pillow-11.3.0-cp312-cp312-macosx_11_0_arm64.whl (4.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.7/4.7 MB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m  \u001b[33m0:00:01\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading propcache-0.3.2-cp312-cp312-macosx_11_0_arm64.whl (43 kB)\n",
      "Downloading protobuf-6.32.1-cp39-abi3-macosx_10_9_universal2.whl (426 kB)\n",
      "Downloading pyparsing-3.2.3-py3-none-any.whl (111 kB)\n",
      "Downloading pytz-2025.2-py2.py3-none-any.whl (509 kB)\n",
      "Downloading PyYAML-6.0.2-cp312-cp312-macosx_11_0_arm64.whl (173 kB)\n",
      "Downloading referencing-0.36.2-py3-none-any.whl (26 kB)\n",
      "Downloading rpds_py-0.27.1-cp312-cp312-macosx_11_0_arm64.whl (345 kB)\n",
      "Downloading scipy-1.16.2-cp312-cp312-macosx_14_0_arm64.whl (20.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m20.9/20.9 MB\u001b[0m \u001b[31m16.1 MB/s\u001b[0m  \u001b[33m0:00:01\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading setuptools-80.9.0-py3-none-any.whl (1.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m16.6 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading sympy-1.14.0-py3-none-any.whl (6.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.3/6.3 MB\u001b[0m \u001b[31m24.1 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m536.2/536.2 kB\u001b[0m \u001b[31m17.4 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading tenacity-9.1.2-py3-none-any.whl (28 kB)\n",
      "Downloading threadpoolctl-3.6.0-py3-none-any.whl (18 kB)\n",
      "Downloading tqdm-4.67.1-py3-none-any.whl (78 kB)\n",
      "Downloading tzdata-2025.2-py2.py3-none-any.whl (347 kB)\n",
      "Downloading werkzeug-3.1.3-py3-none-any.whl (224 kB)\n",
      "Downloading MarkupSafe-3.0.2-cp312-cp312-macosx_11_0_arm64.whl (12 kB)\n",
      "Downloading filelock-3.19.1-py3-none-any.whl (15 kB)\n",
      "Downloading jinja2-3.1.6-py3-none-any.whl (134 kB)\n",
      "Downloading networkx-3.5-py3-none-any.whl (2.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m16.0 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading zope.interface-7.2-cp312-cp312-macosx_11_0_arm64.whl (209 kB)\n",
      "Installing collected packages: pytz, mpmath, fastjsonschema, wxPython, tzdata, typing-extensions, tqdm, threadpoolctl, tensorboard-data-server, tenacity, sympy, setuptools, rpds-py, PyYAML, pyparsing, protobuf, propcache, pillow, numpy, networkx, multidict, MarkupSafe, markdown, kiwisolver, joblib, idna, grpcio, fsspec, frozenlist, fonttools, filelock, cycler, attrs, aiohappyeyeballs, absl-py, zope.interface, yarl, werkzeug, scipy, referencing, plotly, pandas, lightning-utilities, jinja2, holidays, contourpy, aiosignal, torch, tensorboard, scikit-learn, matplotlib, jsonschema-specifications, datetime, aiohttp, torchmetrics, seaborn, jsonschema, captum, pytorch-lightning, nbformat, neuralprophet\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61/61\u001b[0m [neuralprophet]0m [nbformat]ightning]\n",
      "\u001b[1A\u001b[2KSuccessfully installed MarkupSafe-3.0.2 PyYAML-6.0.2 absl-py-2.3.1 aiohappyeyeballs-2.6.1 aiohttp-3.12.15 aiosignal-1.4.0 attrs-25.3.0 captum-0.8.0 contourpy-1.3.3 cycler-0.12.1 datetime-5.5 fastjsonschema-2.21.2 filelock-3.19.1 fonttools-4.59.2 frozenlist-1.7.0 fsspec-2025.9.0 grpcio-1.74.0 holidays-0.80 idna-3.10 jinja2-3.1.6 joblib-1.5.2 jsonschema-4.25.1 jsonschema-specifications-2025.9.1 kiwisolver-1.4.9 lightning-utilities-0.15.2 markdown-3.9 matplotlib-3.10.6 mpmath-1.3.0 multidict-6.6.4 nbformat-5.10.4 networkx-3.5 neuralprophet-0.8.0 numpy-1.26.4 pandas-2.3.2 pillow-11.3.0 plotly-5.24.1 propcache-0.3.2 protobuf-6.32.1 pyparsing-3.2.3 pytorch-lightning-1.9.5 pytz-2025.2 referencing-0.36.2 rpds-py-0.27.1 scikit-learn-1.7.2 scipy-1.16.2 seaborn-0.13.2 setuptools-80.9.0 sympy-1.14.0 tenacity-9.1.2 tensorboard-2.20.0 tensorboard-data-server-0.7.2 threadpoolctl-3.6.0 torch-2.8.0 torchmetrics-1.8.2 tqdm-4.67.1 typing-extensions-4.15.0 tzdata-2025.2 werkzeug-3.1.3 wxPython-4.2.3 yarl-1.20.1 zope.interface-7.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pandas datetime matplotlib seaborn neuralprophet scikit-learn torch wxPython statsmodels openpyxl kaleido --upgrade plotly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "absl-py==2.3.1\n",
      "aiohappyeyeballs==2.6.1\n",
      "aiohttp==3.12.15\n",
      "aiosignal==1.4.0\n",
      "appnope==0.1.4\n",
      "asttokens==3.0.0\n",
      "attrs==25.3.0\n",
      "captum==0.8.0\n",
      "comm==0.2.3\n",
      "contourpy==1.3.3\n",
      "cycler==0.12.1\n",
      "DateTime==5.5\n",
      "debugpy==1.8.16\n",
      "decorator==5.2.1\n",
      "executing==2.2.1\n",
      "fastjsonschema==2.21.2\n",
      "filelock==3.19.1\n",
      "fonttools==4.59.2\n",
      "frozenlist==1.7.0\n",
      "fsspec==2025.9.0\n",
      "grpcio==1.74.0\n",
      "holidays==0.80\n",
      "idna==3.10\n",
      "ipykernel==6.30.1\n",
      "ipython==9.5.0\n",
      "ipython_pygments_lexers==1.1.1\n",
      "jedi==0.19.2\n",
      "Jinja2==3.1.6\n",
      "joblib==1.5.2\n",
      "jsonschema==4.25.1\n",
      "jsonschema-specifications==2025.9.1\n",
      "jupyter_client==8.6.3\n",
      "jupyter_core==5.8.1\n",
      "kiwisolver==1.4.9\n",
      "lightning-utilities==0.15.2\n",
      "Markdown==3.9\n",
      "MarkupSafe==3.0.2\n",
      "matplotlib==3.10.6\n",
      "matplotlib-inline==0.1.7\n",
      "mpmath==1.3.0\n",
      "multidict==6.6.4\n",
      "nbformat==5.10.4\n",
      "nest-asyncio==1.6.0\n",
      "networkx==3.5\n",
      "neuralprophet==0.8.0\n",
      "numpy==1.26.4\n",
      "packaging==25.0\n",
      "pandas==2.3.2\n",
      "parso==0.8.5\n",
      "pexpect==4.9.0\n",
      "pillow==11.3.0\n",
      "platformdirs==4.4.0\n",
      "plotly==5.24.1\n",
      "prompt_toolkit==3.0.52\n",
      "propcache==0.3.2\n",
      "protobuf==6.32.1\n",
      "psutil==7.0.0\n",
      "ptyprocess==0.7.0\n",
      "pure_eval==0.2.3\n",
      "Pygments==2.19.2\n",
      "pyparsing==3.2.3\n",
      "python-dateutil==2.9.0.post0\n",
      "pytorch-lightning==1.9.5\n",
      "pytz==2025.2\n",
      "PyYAML==6.0.2\n",
      "pyzmq==27.1.0\n",
      "referencing==0.36.2\n",
      "rpds-py==0.27.1\n",
      "scikit-learn==1.7.2\n",
      "scipy==1.16.2\n",
      "seaborn==0.13.2\n",
      "setuptools==80.9.0\n",
      "six==1.17.0\n",
      "stack-data==0.6.3\n",
      "sympy==1.14.0\n",
      "tenacity==9.1.2\n",
      "tensorboard==2.20.0\n",
      "tensorboard-data-server==0.7.2\n",
      "threadpoolctl==3.6.0\n",
      "torch==2.8.0\n",
      "torchmetrics==1.8.2\n",
      "tornado==6.5.2\n",
      "tqdm==4.67.1\n",
      "traitlets==5.14.3\n",
      "typing_extensions==4.15.0\n",
      "tzdata==2025.2\n",
      "wcwidth==0.2.13\n",
      "Werkzeug==3.1.3\n",
      "wxPython==4.2.3\n",
      "yarl==1.20.1\n",
      "zope.interface==7.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip freeze"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import warnings\n",
    "import pyarrow.parquet as pq\n",
    "from sklearn.model_selection import train_test_split\n",
    "from scipy import stats\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from statsmodels.tsa.stattools import kpss\n",
    "from statsmodels.tsa.api import VAR\n",
    "from statsmodels.graphics.tsaplots import plot_acf\n",
    "from statsmodels.graphics.tsaplots import plot_pacf\n",
    "from statsmodels.tools.eval_measures import aic, bic\n",
    "from datetime import datetime\n",
    "from statsmodels.tsa.stattools import acf\n",
    "from statsmodels.graphics.tsaplots import plot_acf\n",
    "from hyperopt import hp, Trials\n",
    "from hyperopt import fmin, tpe\n",
    "from hyperopt import STATUS_OK\n",
    "from dateutil.relativedelta import relativedelta\n",
    "import ipywidgets as widgets\n",
    "import torch  \n",
    "import statsmodels.api as sm\n",
    "from pandas import pivot_table\n",
    "from pandas._libs.tslibs.parsing import DateParseError\n",
    "import matplotlib \n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import display\n",
    "from tabulate import tabulate\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import gui\n",
    "from dateutil.relativedelta import relativedelta\n",
    "import GrangerCausality\n",
    "import NP_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lectura de bases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = gui.select_file_via_gui(window_title=\"Seleccione el archivo con datos historicos\")\n",
    "if df is not None:\n",
    "    col_fecha = gui.select_column_from_dataframe(df, window_title=\"Seleccione la columna de fecha\")\n",
    "    if col_fecha:\n",
    "        print(f\"Selected column: {col_fecha}\")\n",
    "    else:\n",
    "        print(\"No column selected.\")\n",
    "\n",
    "    col_pred = gui.select_column_from_dataframe(df, window_title=\"Seleccione la columna para la predicción\")\n",
    "    if col_pred:\n",
    "        print(f\"Selected column: {col_pred}\")\n",
    "    else:\n",
    "        print(\"No column selected.\")\n",
    "else:\n",
    "    print(\"No file selected or failed to load.\")\n",
    "\n",
    "\n",
    "VarsEco_Base = gui.select_file_via_gui(window_title=\"Seleccione el archivo con las variables economicas (Escenario Base)\")\n",
    "if VarsEco_Base is not None:\n",
    "    VarsEco_Base.head()\n",
    "else:\n",
    "    print(\"No file selected or failed to load.\")\n",
    "\n",
    "VarsEco_Adv = gui.select_file_via_gui(window_title=\"Seleccione el archivo con las variables economicas (Escenario Adverso)\")\n",
    "if VarsEco_Adv is not None:\n",
    "    VarsEco_Adv.head()\n",
    "else:\n",
    "    print(\"No file selected or failed to load.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Definimos columnas de añomes como strings\n",
    "try:\n",
    "    df['aniomes'] = pd.to_datetime(df[col_fecha]).dt.strftime('%Y%m')\n",
    "except DateParseError as e:\n",
    "    if len(df[col_fecha].max()) != 6:\n",
    "        print(\"Error: Revisar el formato de la columna de fecha. Asegurar que venga en formato de añomes(AAAAMM) o de fecha-hora.\")\n",
    "        \n",
    "VarsEco_Base['aniomes'] = VarsEco_Base['aniomes'].astype(str)\n",
    "VarsEco_Adv['aniomes'] = VarsEco_Adv['aniomes'].astype(str)\n",
    "fecha_real = df['aniomes'].max()\n",
    "\n",
    "Eco_Base = VarsEco_Base[VarsEco_Base['aniomes']<= fecha_real]\n",
    "Eco_Base.head()\n",
    "\n",
    "Eco_Adv = VarsEco_Adv[VarsEco_Adv['aniomes']<= fecha_real]\n",
    "Eco_Adv.head()\n",
    "\n",
    "same = (Eco_Base.columns==Eco_Adv.columns).all()\n",
    "if same:\n",
    "    print(\"The column names have the same order.\")\n",
    "else:\n",
    "    print(\"The column names do not have the same order.\")\n",
    "\n",
    "\n",
    "Bs_Hist=df.merge(Eco_Base, how='left', on='aniomes')\n",
    "Bs_Hist.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forecast=len(VarsEco_Base)-len(Eco_Base)\n",
    "forecast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Additional variables to include in all DataFrames\n",
    "additional_vars = ['Fondeo1dia', 'Cetes28', 'Cetes91', 'Cetes182', 'Cetes364', \n",
    "                   'BonoM3', 'BonoM5', 'BonoM10', 'TasaFedEUA', 'Tbill1m', 'Tbill3m', \n",
    "                   'Tbill6m', 'Tbill12m', 'Tnote3A', 'Tnote5A', 'Tnote10A', 'InflacionAn', \n",
    "                   'MXNaUSD', 'USDaEUR', 'CambioPIB_anual', 'Desempleo', 'IPC', \n",
    "                   'SyP', 'ExpNoPetro', 'VIX_BMV', 'VIX_USA']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "fecha_train=input(\"Ingrese el añomes para hacer el corte de train/test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_inicial = Bs_Hist[['aniomes', col_pred] + additional_vars].reset_index(drop=True).copy()\n",
    "df_inicial.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 895 entries, 0 to 894\n",
      "Data columns (total 28 columns):\n",
      " #   Column           Non-Null Count  Dtype         \n",
      "---  ------           --------------  -----         \n",
      " 0   ds               895 non-null    datetime64[ns]\n",
      " 1   y                895 non-null    int64         \n",
      " 2   Fondeo1dia       895 non-null    float64       \n",
      " 3   Cetes28          895 non-null    float64       \n",
      " 4   Cetes91          895 non-null    float64       \n",
      " 5   Cetes182         895 non-null    float64       \n",
      " 6   Cetes364         895 non-null    float64       \n",
      " 7   BonoM3           895 non-null    float64       \n",
      " 8   BonoM5           895 non-null    float64       \n",
      " 9   BonoM10          895 non-null    float64       \n",
      " 10  TasaFedEUA       895 non-null    float64       \n",
      " 11  Tbill1m          895 non-null    float64       \n",
      " 12  Tbill3m          895 non-null    float64       \n",
      " 13  Tbill6m          895 non-null    float64       \n",
      " 14  Tbill12m         895 non-null    float64       \n",
      " 15  Tnote3A          895 non-null    float64       \n",
      " 16  Tnote5A          895 non-null    float64       \n",
      " 17  Tnote10A         895 non-null    float64       \n",
      " 18  InflacionAn      895 non-null    float64       \n",
      " 19  MXNaUSD          895 non-null    float64       \n",
      " 20  USDaEUR          895 non-null    float64       \n",
      " 21  CambioPIB_anual  895 non-null    float64       \n",
      " 22  Desempleo        895 non-null    float64       \n",
      " 23  IPC              895 non-null    float64       \n",
      " 24  SyP              895 non-null    float64       \n",
      " 25  ExpNoPetro       895 non-null    float64       \n",
      " 26  VIX_BMV          895 non-null    float64       \n",
      " 27  VIX_USA          895 non-null    float64       \n",
      "dtypes: datetime64[ns](1), float64(26), int64(1)\n",
      "memory usage: 195.9 KB\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# Rename the selected columns\n",
    "df_inicial.rename(columns={'aniomes':'ds'},inplace=True)\n",
    "df_inicial.rename(columns={col_pred:'y'},inplace=True)\n",
    "df_inicial['ds']=(df_inicial['ds'].astype(str).str[0:4])+'-'+(df_inicial['ds'].astype(str).str[4:6])+'-'+'01'\n",
    "df_inicial['ds']=pd.to_datetime(df_inicial['ds'])\n",
    "df_inicial.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "date_train = datetime.strptime(str(fecha_train),\"%Y%m\")\n",
    "date_train = datetime.strftime(date_train,\"%Y-%m-01\")\n",
    "date_train = pd.to_datetime(date_train)\n",
    "\n",
    "df_train = df_inicial[df_inicial['ds']<= date_train]\n",
    "df_train.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pruebas de Granger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stationary_info = GrangerCausality.make_series_stationary(df_train)\n",
    "\n",
    "# Create a new DataFrame with differenced variables\n",
    "differenced_df = GrangerCausality.make_differenced_dataframe(df_train, stationary_info)\n",
    "\n",
    "\n",
    "# Perform Granger causality test with automatic lag selection based on SSR Chi-Square test\n",
    "granger_results = GrangerCausality.granger_causality_test(differenced_df, 'y', test='ssr_chi2test')\n",
    "\n",
    "print(\"Granger Causality Test Results using SSR Chi-Square Test:\")\n",
    "for variable, result in granger_results.items():\n",
    "    print(f\"{variable}: p-value = {result['p_value']}, Best Lag = {result['best_lag']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract significant variables and their p-values\n",
    "significant_variables = [(variable, result['p_value']) for variable, result in granger_results.items() if result['p_value'] <= 0.05]\n",
    "\n",
    "# Create a DataFrame from the list\n",
    "tabla1=pd.DataFrame(significant_variables, columns=['Variable', 'p-value'])\n",
    "\n",
    "tabla1\n",
    "# Print the results\n",
    "#print(\"Significant Variables (p-value <= 0.05):\")\n",
    "#for variable, p_value in significant_variables_list:\n",
    "#    print(f\"{variable}: p-value = {p_value}\")\n",
    "\n",
    "# Extract significant variables as a list\n",
    "significant_variables_list = [variable for variable, result in granger_results.items() if result['p_value'] <= 0.05]\n",
    "future_regressor=significant_variables_list\n",
    "future_regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "data = {'Name': ['Alice', 'Bob', 'Charlie', 'David', 'Eve', 'Frank'],\n",
    "        'Age': [25, 30, 35, 40, 45, 50],\n",
    "        'City': ['New York', 'London', 'Paris', 'Tokyo', 'Sydney', 'Rome']}\n",
    "df = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_red=Bs_Hist[['ds','y'] + future_regressor]\n",
    "df_red.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_end_date = date_train\n",
    "test_start_date = train_end_date + pd.DateOffset(months=1)\n",
    "\n",
    "fecha_real_formato = datetime.strptime(str(fecha_real),\"%Y%m\")\n",
    "fecha_real_formato = datetime.strftime(fecha_real_formato,\"%Y-%m-01\")\n",
    "fecha_real_formato = pd.to_datetime(fecha_real_formato)\n",
    "\n",
    "rel = relativedelta(train_end_date, fecha_real_formato)\n",
    "forecast = abs(rel.years * 12 + rel.months)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "basic=df_red[['ds','y']+ future_regressor]\n",
    "\n",
    "# Filter the data based on the cutoff date\n",
    "df_train = basic[basic['ds'] < test_start_date]\n",
    "df_test = basic[basic['ds'] >= test_start_date]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "next_months_df= basic[basic['ds'] >= test_start_date]\n",
    "next_months_df=next_months_df[['ds']+ future_regressor]\n",
    "next_months_df['y']=None\n",
    "next_months_df=next_months_df[['ds','y']+ future_regressor]\n",
    "df_train_f=pd.concat([df_train,next_months_df],ignore_index=True)\n",
    "df_train_f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = NP_model.find_best_lr(basic, test_start_date, forecast, future_regressor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the dataset into train and test sets\n",
    "df_train = basic[basic['ds'] < test_start_date].copy()\n",
    "df_test = basic[basic['ds'] >= test_start_date].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Evaluates and saves all errors to a single CSV file for later analysis\n",
    "NP_model.regressor_error(basic, df_train, df_test, lr, test_start_date, forecast, future_regressor)\n",
    "\n",
    "#Model training\n",
    "importance_scores = NP_model.get_importance_scores(basic, df_train, df_test, lr, test_start_date, forecast, future_regressor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare data for plotting\n",
    "variables = [var for var, score in importance_scores]\n",
    "scores = [score for var, score in importance_scores]\n",
    "\n",
    "# Create a DataFrame for seaborn\n",
    "df_importance = pd.DataFrame({'Variable': variables, 'Importance Score': scores})\n",
    "\n",
    "# Create a horizontal bar plot\n",
    "fig = plt.figure(figsize=(10, 6))\n",
    "sns.barplot(x='Importance Score', y='Variable', data=df_importance, palette='viridis')\n",
    "plt.xlabel('Importance Score')\n",
    "plt.ylabel('Variable')\n",
    "plt.title('Variable Importance Scores')\n",
    "plt.grid(axis='x', linestyle='--', alpha=0.7)\n",
    "plt.show()\n",
    "fig.savefig('Importance_Scores.png', dpi=fig.dpi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m, metrics = NP_model.train_model(df_train, df_test, lr, forecast, future_regressor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a larger figure\n",
    "fig = plt.figure(figsize=(12, 6))\n",
    "\n",
    "# Plot training loss curve\n",
    "plt.plot(metrics['Loss'], label='Training Loss', color='blue')\n",
    "\n",
    "# Plot validation loss curve\n",
    "plt.plot(metrics['Loss_val'], label='Validation Loss', color='orange')\n",
    "\n",
    "# Add labels and legend\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.legend()\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n",
    "\n",
    "fig.savefig('Model_Loss.png', dpi=fig.dpi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m.plot_parameters().savefig('Model_Parameters.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for variable, result in granger_results.items():\n",
    "    if variable in future_regressor:\n",
    "        print(f\"{variable}: Best Lag = {result['best_lag']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_forecast=m.predict(df_train_f)\n",
    "# Visualize the forecast\n",
    "m.plot(df_train_forecast)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dd= df_train_forecast.merge(basic[['ds','y']], left_on='ds', right_on='ds', how='outer')\n",
    "dd[['ds','y_y','yhat1']].tail(forecast+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract 'ds', 'yhat1', and 'y_y' columns from the DataFrame\n",
    "ds = dd['ds']\n",
    "yhat1 = dd['yhat1']\n",
    "y_y = dd['y_y']\n",
    "\n",
    "# Plot the data\n",
    "fig = plt.figure(figsize=(10, 6))\n",
    "plt.plot(ds, yhat1, label='yhat1', color='blue')\n",
    "plt.plot(ds, y_y, label='y_y', color='green')\n",
    "plt.axvline(x=train_end_date, color='red', linestyle='--', label='train_end_date')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Value')\n",
    "plt.title('Comparison of yhat1 and y_y')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "fig.savefig('Comparacion.png', dpi=fig.dpi)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(VarsEco_Base.aniomes.max())\n",
    "print(VarsEco_Adv.aniomes.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Esc_Base=VarsEco_Base.loc[VarsEco_Base['aniomes']>fecha_real,['aniomes']+future_regressor]\n",
    "# Rename the selected columns\n",
    "Esc_Base.rename(columns={'aniomes':'ds'},inplace=True)\n",
    "Esc_Base['ds']=(Esc_Base['ds'].astype(str).str[0:4])+'-'+(Esc_Base['ds'].astype(str).str[4:6])+'-'+'01'\n",
    "Esc_Base['ds']=pd.to_datetime(Esc_Base['ds'])\n",
    "Esc_Base['y']=None\n",
    "Esc_Base=Esc_Base[['ds','y']+ future_regressor]\n",
    "df_base=pd.concat([basic,Esc_Base],ignore_index=True)\n",
    "#df_base['covid']=df_base['covid'].fillna(0)\n",
    "df_base.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forecast = len(Esc_Base)\n",
    "forecast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = m.fit(basic,freq='MS');\n",
    "metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_base_forecast=m.predict(df_base)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m.plot(df_base_forecast)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(basic.loc[basic['y']==basic['y'].max(),'ds'])\n",
    "print(basic.loc[basic['y']==basic['y'].min(),'ds'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Esc_Adv=VarsEco_Adv.loc[VarsEco_Adv['aniomes']>fecha_real,['aniomes']+future_regressor]\n",
    "# Rename the selected columns\n",
    "Esc_Adv.rename(columns={'aniomes':'ds'},inplace=True)\n",
    "Esc_Adv['ds']=(Esc_Adv['ds'].astype(str).str[0:4])+'-'+(Esc_Adv['ds'].astype(str).str[4:6])+'-'+'01'\n",
    "Esc_Adv['ds']=pd.to_datetime(Esc_Adv['ds'])\n",
    "Esc_Adv['y']=None\n",
    "Esc_Adv=Esc_Adv[['ds','y']+ future_regressor]\n",
    "df_Adv=pd.concat([basic,Esc_Adv],ignore_index=True)\n",
    "#df_Adv['covid']=df_Adv['covid'].fillna(0)\n",
    "df_Adv.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_Adv_forecast=m.predict(df_Adv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m.plot(df_Adv_forecast)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_base_forecast.rename(columns={'yhat1':'y_Base'},inplace=True)\n",
    "df_Adv_forecast.rename(columns={'yhat1':'y_Adv'},inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MiPyMes1Estres= df_base_forecast.merge(df_Adv_forecast[['ds','y_Adv']], left_on='ds', right_on='ds', how='outer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract 'ds', 'yhat1', and 'y_y' columns from the DataFrame\n",
    "ds = MiPyMes1Estres['ds']\n",
    "yBase = MiPyMes1Estres['y_Base']\n",
    "yAdv = MiPyMes1Estres['y_Adv']\n",
    "yReal = MiPyMes1Estres['y']\n",
    "\n",
    "# Plot the data\n",
    "fig = plt.figure(figsize=(10, 6))\n",
    "plt.plot(ds, yBase, label='yBase', color='blue')\n",
    "plt.plot(ds, yAdv, label='yAdv', color='green')\n",
    "plt.plot(ds, yReal, label='yReal', color='black')\n",
    "plt.axvline(x=basic.ds.max(), color='red', linestyle='--', label='real')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Value')\n",
    "plt.title('Comparison of MiPyMes Etapa 1')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "fig.savefig('Forecast.png', dpi=fig.dpi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'lightning'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlightning\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpytorch\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Trainer\n\u001b[32m      3\u001b[39m \u001b[38;5;66;03m# To save logs and checkpoints to a specific local directory\u001b[39;00m\n\u001b[32m      4\u001b[39m trainer = Trainer(default_root_dir=\u001b[33m\"\u001b[39m\u001b[33m/your/path/to/save/experiments\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'lightning'"
     ]
    }
   ],
   "source": [
    "from lightning.pytorch import Trainer\n",
    "\n",
    "# To save logs and checkpoints to a specific local directory\n",
    "trainer = Trainer(default_root_dir=\"/your/path/to/save/experiments\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
